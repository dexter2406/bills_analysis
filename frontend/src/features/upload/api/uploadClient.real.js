import { requestJson } from "../../../lib/http";
import {
  parseBatchListResponse,
  parseBatchResponse,
  parseCreateBatchRequest,
  parseCreateBatchUploadTaskResponse,
  parseMergeRequest,
  parseMergeTaskResponse,
  parseSubmitReviewRequest,
} from "../../../contracts/v1.schema";

/**
 * Build a real upload client wired to backend /v1 endpoints.
 * @param {{ baseUrl: string; fetchImpl?: typeof fetch }} params
 */
export function createRealUploadClient({ baseUrl, fetchImpl }) {
  return {
    mode: "real",

    /**
     * Keep compatibility path for legacy non-multipart create flow.
     * @param {File[]} files
     * @param {{ batchType: "daily" | "office" }} context
     */
    async uploadFiles(files, context) {
      const defaultCategory = context.batchType === "daily" ? "bar" : "office";
      return files.map((file) => ({
        path: `/virtual-upload/${Date.now()}-${safeName(file.name)}`,
        category: defaultCategory,
      }));
    },

    /**
     * Create batch from multipart upload.
     * @param {{
     *  files: Array<{ file: File; category: "bar" | "zbon" | "office" | null; name: string }>;
     *  batchType: "daily" | "office";
     *  runDate: string | null;
     *  metadata?: Record<string, unknown>;
     * }} payload
     */
    async createBatchUpload(payload) {
      const body = buildUploadFormData(payload);
      const data = await requestJson({
        baseUrl,
        path: "/v1/batches/upload",
        method: "POST",
        body,
        fetchImpl,
      });
      return parseCreateBatchUploadTaskResponse(data);
    },

    /**
     * @param {unknown} payload
     */
    async createBatch(payload) {
      const body = parseCreateBatchRequest(payload);
      const data = await requestJson({
        baseUrl,
        path: "/v1/batches",
        method: "POST",
        body,
        fetchImpl,
      });
      return parseBatchResponse(data);
    },

    /**
     * @param {string} batchId
     */
    async getBatch(batchId) {
      const data = await requestJson({
        baseUrl,
        path: `/v1/batches/${batchId}`,
        method: "GET",
        fetchImpl,
      });
      return parseBatchResponse(data);
    },

    /**
     * @param {number} [limit]
     */
    async listBatches(limit = 100) {
      const data = await requestJson({
        baseUrl,
        path: `/v1/batches?limit=${limit}`,
        method: "GET",
        fetchImpl,
      });
      return parseBatchListResponse(data);
    },

    /**
     * @param {string} batchId
     * @param {unknown} payload
     */
    async submitReview(batchId, payload) {
      const body = parseSubmitReviewRequest(payload);
      const data = await requestJson({
        baseUrl,
        path: `/v1/batches/${batchId}/review`,
        method: "PUT",
        body,
        fetchImpl,
      });
      return parseBatchResponse(data);
    },

    /**
     * @param {string} batchId
     * @param {unknown} payload
     */
    async queueMerge(batchId, payload) {
      const body = parseMergeRequest(payload);
      const data = await requestJson({
        baseUrl,
        path: `/v1/batches/${batchId}/merge`,
        method: "POST",
        body,
        fetchImpl,
      });
      return parseMergeTaskResponse(data);
    },

    /**
     * Fetch review rows generated by backend for one batch.
     * @param {string} batchId
     */
    async getReviewRows(batchId) {
      const data = await requestJson({
        baseUrl,
        path: `/v1/batches/${batchId}/review-rows`,
        method: "GET",
        fetchImpl,
      });
      return parseReviewRowsPayload(data);
    },

    /**
     * Upload local excel merge source and return backend path.
     * @param {string} batchId
     * @param {File} file
     */
    async uploadMergeSourceLocal(batchId, file) {
      const body = new FormData();
      body.append("file", file, file.name);

      const data = await requestJson({
        baseUrl,
        path: `/v1/batches/${batchId}/merge-source/local`,
        method: "POST",
        body,
        fetchImpl,
      });
      return parseLocalMergeSourcePayload(data);
    },
  };
}

/**
 * Sanitize file names for virtual upload paths.
 * @param {string} value
 */
function safeName(value) {
  return value.replace(/[^a-zA-Z0-9._-]/g, "_");
}

/**
 * Build multipart payload for /v1/batches/upload.
 * @param {{
 *  files: Array<{ file: File; category: "bar" | "zbon" | "office" | null; name: string }>;
 *  batchType: "daily" | "office";
 *  runDate: string | null;
 *  metadata?: Record<string, unknown>;
 * }} payload
 */
function buildUploadFormData(payload) {
  const formData = new FormData();
  formData.set("type", payload.batchType);
  if (payload.runDate) {
    formData.set("run_date", payload.runDate);
  }
  formData.set("metadata_json", JSON.stringify(payload.metadata || {}));

  if (payload.batchType === "daily") {
    const zbonFiles = payload.files.filter((entry) => entry.category === "zbon");
    if (zbonFiles.length !== 1) {
      throw new Error("Daily upload requires exactly one ZBON file.");
    }

    formData.append("zbon_file", zbonFiles[0].file, zbonFiles[0].name);
    for (const barFile of payload.files.filter((entry) => entry.category === "bar")) {
      formData.append("bar_files", barFile.file, barFile.name);
    }
    return formData;
  }

  const officeFiles = payload.files.filter((entry) => entry.category === "office");
  if (!officeFiles.length) {
    throw new Error("Office upload requires at least one office file.");
  }
  for (const officeFile of officeFiles) {
    formData.append("office_files", officeFile.file, officeFile.name);
  }
  return formData;
}

/**
 * Parse evolving review rows response envelope safely.
 * @param {unknown} payload
 */
function parseReviewRowsPayload(payload) {
  if (Array.isArray(payload)) {
    return { rows: payload };
  }
  if (payload && typeof payload === "object" && Array.isArray(payload.rows)) {
    return { rows: payload.rows };
  }
  return { rows: [] };
}

/**
 * Parse local merge source upload response.
 * @param {unknown} payload
 */
function parseLocalMergeSourcePayload(payload) {
  if (payload && typeof payload === "object" && typeof payload.monthly_excel_path === "string") {
    return { monthly_excel_path: payload.monthly_excel_path };
  }
  throw new Error("Invalid merge source response.");
}
